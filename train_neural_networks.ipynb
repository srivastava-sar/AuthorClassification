{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_39 to have shape (10000,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-95f5fd0f3fda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# output layer = no. of classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mtrain_histt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_39 to have shape (10000,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "dataset = pd.read_csv('features.csv')\n",
    "names = ['authorID', 'spCount','hastags','word_count','char_count','isCapitalize']\n",
    "X = dataset.iloc[:, 2:].values\n",
    "y = dataset.iloc[:,1].values\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "#dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "dummy_y=encoded_Y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.20,random_state=42)\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=5, activation='relu')) # input dimension = dimension of festure vector\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(10000, activation='softmax')) # output layer = no. of classes\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "train_histt = model.fit(X_train, y_train, epochs=10, batch_size=512, verbose=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAQMklEQVR4nO3d349c9XnH8c8zZ2b2lw1e4yUVNngJqkhTpBQYWgISF5BIbRMlF+0FlUhbpMo3bUKiqFFSVco/EEVJpSqqQ5KboObC4SJKo5SqSS7SC8TaRuWHSROBbczPBdvY7No7v55enDOzM7Oz3rE9h/N45/2SVuec7/me7zw+2J85890zHHN3AQDiKhVdAADg0ghqAAiOoAaA4AhqAAiOoAaA4Mp5DLpnzx5fXFzMY2gA2JYOHz78jrsvDNuXS1AvLi5qaWkpj6EBYFsysxOb7WPqAwCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCy+U+6iv1L//9W+2bn9E9i7u1b35GZlZ0SQBQuDBBvdZs6fv/84rOrjYkSR+6bkq1xd26Z/+8aou79ZHf26lywgcAAJMnTFBPlRMd/udP6v/eOq+l46f1zPEzOnzijP7jf9+QJM1VE921f161/bt1z+K8/uiWXZqthikfAHJjeTzhpVar+bi+Qv7a2QtaOn5aS8fP6Jnjp/Wbt87LXUpKpj+86bpucN+9OK8bd06P5TUB4INmZofdvTZ0X/SgHvTehYaOnjzTDe5nXz2rtWZbkrR4w2w6XbI4r7v379ZtC3PMcwO4JmyroB5Ub7b1/Ovvda+6l06c0emVuiRp91xVd++f1z2L6Tz3HTddr2qZeW4A8WzroB7k7nr5nZW+ee5X3lmRJE2VS/rYzbu6wX3XLfO6fqZSSJ0A0GuignqY5fNrOnwiDe6l46f1/Ovn1Gq7zKTbP7RT9yzuVi0L7727ZoouF8AEmvigHrRab+rZV89257mPnDijlXpLknTT9dO6a/+89s7P6Ia5quZnq7phR7acm9L8XEU7psrMfQMYq0sF9UTe3zZbLeu+2/bovtv2SJKarbZeevO8Dp9Ig/voybN66oW3VG+1hx5fTUqan6to99yUdneWs/3b83OVbrDPz1ZV4R5wAFdoIoN6UDkp6Y691+uOvdfrb+5blJTOda/UWzqzUte7K/Xu8vTKmk6vNPqWz599T+++v6ZzF5ubvsZ102XdsGNK8wOBvmE5W9XuHVXNVROu2gFIIqg3ZWbaMVXWjqmybt49O9IxjVZbZ1brOrPS0LsrazrdE/Dd5Wpdp86s6rnX6jq9UlejNXzqqVouaddMRXNTZc1UEs1WE81Us2Ul0Uy1rNlqT3sl0Wy1rOnueqd/ue/Y6XKiUok3AOBaQlCPUSUp6cad09kXb3Zu2d/d9f5aU6cHw3wlDfEzq3Wt1lu6UG9ptd7SuYtNvX1uTauNZrftQqOly/01w3SlpNnq+htAJ8hnsrCf6XsDKGumWtJUOVG1XNJUuX99WNtUpaSpJNFUpaRqUuKNAbhKBHWBzEw7pyvaOV3R/hvmrmgMd9fFRlur9aYuNNZDPQ3xZjfoLzR62usb2y/UW1p+f02r9dW+9npz+Dz95agkNhD0nYBP+sJ+Y9t62HeW1XJJlaTzY6p21sul7HV696fHVMrWv52YkpIxtYRrBkF9jTOz9Gq4muQyfrPV1sVmW/VmW2vNltYabdVbba010u20vfPT0lq3b//+TY/P1s9fbHb79I5Zb7Y3/aXu1TBTX3BXsjeB9eDfGO7dN4SSqZy1lUsllbN95ay9mqTLcilrT0yVrF85WT++t31wrMqmx6frfEqZLAQ1LqmclLQjKUlTxdXQbnsa6M22mq22Gi1XI9tutNZ/6k3v3265Gs2B7Va727bWaqvRc0y9M3azd7utC42Wzl1cf9Notjyto50umy1Xo50e22qP/3bXYUqm7ptBkv2Uu8tS33ZSSgM+KZV6+vQus/Zkk/bOdme/ZfuyTyaJmUolU2Lp/4On1Ndm3baSaWh72qYNbUnJVLLOn0Hd9fU262lT9hrpsdapxdJ91/qnJ4Ia4ZVKpulSoulKPp8axsnd1Wi5mllwN1ttNdvpm0Gzrz0N98HQ77wJ9fbbfCxXq93Oltl21t72nv2tnv3tznhtXWhk26319v5+nf0b2681ZuqGdrrsTH+pL+wtC/ru+sCbQO/xnTeX3n67Zqv67l8PvRX6qhDUwBiZmaplU3UbPzzJ3dV2dYO91Xa121LLs/Vs2bvezo4Z1t5qq/84d7XbA/t72rrrfW2dutZfx4etd/q00+0N677+Z2m7y329tt71zut0avZsPcnpyn2koDazL0n6O0ku6TlJj7r7xVwqAhBaetUpJaX4n3C2iy3f9s1sr6QvSKq5+x2SEkkP510YACA16uezsqQZMytLmpX0en4lAQB6bRnU7v6apG9IOinpDUnvuftTg/3M7ICZLZnZ0vLy8vgrBYAJNcrUx7ykz0q6VdJNkubM7JHBfu5+0N1r7l5bWFgYf6UAMKFGmfr4hKRX3H3Z3RuSnpR0X75lAQA6Rgnqk5LuNbNZS+8af0jSsXzLAgB0jDJH/bSkQ5KOKL01ryTpYM51AQAyI91H7e5fl/T1nGsBAAyxfb8+BQDbBEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMER1AAQHEENAMGNFNRmtsvMDpnZS2Z2zMw+nndhAIBUecR+35b0c3f/SzOrSprNsSYAQI8tg9rMrpP0gKS/lSR3r0uq51sWAKBjlKmPD0talvQDMztqZo+b2dxgJzM7YGZLZra0vLw89kIBYFKNEtRlSXdJ+o673ylpRdJXBzu5+0F3r7l7bWFhYcxlAsDkGiWoT0k65e5PZ9uHlAY3AOADsGVQu/ubkl41s9uzpockvZhrVQCArlHv+vi8pCeyOz5elvRofiUBAHqNFNTu/qykWs61AACG4JuJABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABAcQQ0AwRHUABDcyEFtZomZHTWzn+ZZEACg3+VcUT8m6VhehQAAhhspqM1sn6RPSXo833IAAINGvaL+lqSvSGpv1sHMDpjZkpktLS8vj6U4AMAIQW1mn5b0trsfvlQ/dz/o7jV3ry0sLIytQACYdKNcUd8v6TNmdlzSjyQ9aGY/zLUqAEDXlkHt7l9z933uvijpYUm/cPdHcq8MACCJ+6gBILzy5XR2919J+lUulQAAhuKKGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCCI6gBIDiCGgCC2zKozexmM/ulmR0zsxfM7LEPojAAQKo8Qp+mpC+7+xEz2ynpsJn9l7u/mHNtAACNcEXt7m+4+5Fs/bykY5L25l0YACB1WXPUZrYo6U5JT+dRDABgo5GD2sx2SPqxpC+6+7kh+w+Y2ZKZLS0vL4+zRgCYaCMFtZlVlIb0E+7+5LA+7n7Q3WvuXltYWBhnjQAw0Ua568MkfU/SMXf/Zv4lAQB6jXJFfb+kz0l60MyezX7+POe6AACZLW/Pc/dfS7IPoBYAwBB8MxEAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASA4ghoAgiOoASC4kYLazP7UzH5jZr8zs6/mXRQAYF15qw5mlkj6V0mflHRK0jNm9hN3fzHv4oCJ4p5P380HGcMY28hYzqmkZMtYvWyjjPjHkn7n7i9Lkpn9SNJnJY0/qP/tAalxUd2/QN0Tt8n2KH26XQf3X+qYwf9gA9vDxhi6b9zH6tL7L/v1r3CMLfsP7RRgjBFeYxxjYHLN3Sj942/HPuwoQb1X0qs926ck/clgJzM7IOmAJN1yyy1XVs2e26VWvTNgZ+Qttkfps8l23+ol+mx4vcExLrEvz2OH7h+1z5jHGOw/8ut8wGNsefy4xriM8a547Mut42pfLzD3Mf1ZrnKM6uwYatholKAeVvnGazv3g5IOSlKtVruyy46/+O4VHQYA29kov0w8Jenmnu19kl7PpxwAwKBRgvoZSb9vZreaWVXSw5J+km9ZAICOLac+3L1pZv8g6T8lJZK+7+4v5F4ZAEDSaHPUcvefSfpZzrUAAIbgm4kAEBxBDQDBEdQAEBxBDQDBmY/r++29g5otSzpxhYfvkfTOGMu5lnEu+nE++nE+1m2Hc7Hf3ReG7cglqK+GmS25e63oOiLgXPTjfPTjfKzb7ueCqQ8ACI6gBoDgIgb1waILCIRz0Y/z0Y/zsW5bn4twc9QAgH4Rr6gBAD0IagAILkxQ8wDddWZ2s5n90syOmdkLZvZY0TUVzcwSMztqZj8tupaimdkuMztkZi9lf0c+XnRNRTKzL2X/Tp43s383s+miaxq3EEHd8wDdP5P0UUl/ZWYfLbaqQjUlfdnd/0DSvZL+fsLPhyQ9JulY0UUE8W1JP3f3j0j6mCb4vJjZXklfkFRz9zuU/q+YHy62qvELEdTqeYCuu9cldR6gO5Hc/Q13P5Ktn1f6D3FvsVUVx8z2SfqUpMeLrqVoZnadpAckfU+S3L3u7meLrapwZUkzZlaWNKtt+ASqKEE97AG6ExtMvcxsUdKdkp4utpJCfUvSVyS1iy4kgA9LWpb0g2wq6HEzmyu6qKK4+2uSviHppKQ3JL3n7k8VW9X4RQnqkR6gO2nMbIekH0v6orufK7qeIpjZpyW97e6Hi64liLKkuyR9x93vlLQiaWJ/p2Nm80o/fd8q6SZJc2b2SLFVjV+UoOYBugPMrKI0pJ9w9yeLrqdA90v6jJkdVzol9qCZ/bDYkgp1StIpd+98wjqkNLgn1SckveLuy+7ekPSkpPsKrmnsogQ1D9DtYWamdA7ymLt/s+h6iuTuX3P3fe6+qPTvxS/cfdtdMY3K3d+U9KqZ3Z41PSTpxQJLKtpJSfea2Wz27+YhbcNfro70zMS88QDdDe6X9DlJz5nZs1nbP2XPrgQ+L+mJ7KLmZUmPFlxPYdz9aTM7JOmI0ruljmobfp2cr5ADQHBRpj4AAJsgqAEgOIIaAIIjqAEgOIIaAIIjqAEgOIIaAIL7f4QfZlLZpdlyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_histt.history['loss'])\n",
    "plt.plot(train_histt.history['acc'])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65639/65639 [==============================] - 11s 172us/step\n",
      "Test loss=8.35606016764252\n",
      "Test accuracy=0.010115937171498652\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('Test loss=%s'% scores[0])\n",
    "print('Test accuracy=%s'% scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
